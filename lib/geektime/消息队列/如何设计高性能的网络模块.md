---
dg-publish: true
title: 如何设计高性能的网络模块
createTime: 2023-08-04 23:33  
---

## 网络：如何设计高性能的网络模块

对消息队列来说，网络模块是核心组件之一，网络模块的性能很大程度上决定了消息传输的能力和整体性能

>消息队列是需要满足高吞吐、高可靠、低延时，并支持多语言访问的基础软件，网络模块最需要解决的是性能、稳定性、开发成本三个问题。接下来我们就围绕这三点来思考消息队列网络模块应该怎样设计。

### 网络模块的性能瓶颈分析

![](https://static001.geekbang.org/resource/image/a8/98/a831a39cd1bf783665eb844257c69898.jpg?wh=3228x1488)

对于单个请求来说，请求流程是：客户端（生产者 / 消费者）构建请求后，向服务端发送请求包 -> 服务端接收包后，将包交给业务线程处理 -> 业务线程处理完成后，将结果返回给客户端。其中可能消耗性能的有三个点。

1. 编解码的速度
2. 网络延迟
3. 服务端/客户端网络模块的处理速度


对于并发请求，单个请求维度的问题上，需要处理高并发，高QPS，高流量等场景，主要包含3个方面

1. 高效的连接管理，当客户端和服务端之间的 TCP 连接数很多，如何高效处理、管理连接。
2. 快速处理高并发请求，当客户端和服务端之间的 QPS 很高，如何快速处理（接收、返回）请求。
3. 大流量场景，当客户端和服务端之间的流量很高，如何快速吞吐（读、写）数据。

### 高性能网络模块的设计实现

#### 基于多路复用技术管理 TCP 连接

1. 单条 TCP 连接的复用
2. IO 多路复用技术
	1. 过把多个 IO 的阻塞复用到同一个 selector 的阻塞上，让系统在单线程的情况下可以同时处理多个客户端请求。最大的优势是系统开销小，系统不需要创建额外的进程或者线程，降低了维护的工作量，也节省了资源。
	2. 单机能处理的连接数还是有上限的
		1. 第一个上限是操作系统的 FD 上限，如果连接数超过了 FD 的数量，连接会创建失败
		2. 第二个限制是系统资源的限制，主要是 CPU 和内存。频繁创建、删除或者创建过多连接会消耗大量的物理资源，导致系统负载过高。
```shell
//查看能打开FD的数量 
ulimit -n //用户级限制
cat /proc/sys/fs/file-max  //系统级限制

//临时修改最大数量 
ulimit -n 100000 //将最大值改为100000
```

#### 基于 Reactor 模型处理高并发请求
最合理的方式就是异步的事件驱动模型，可以通过 Epoll 和异步编程来解决。

Reactor 模型是一种处理并发服务请求的事件设计模式，当主流程收到请求后，通过多路分离处理的方式，把请求分发给相应的请求处理器处理。如下图所示，Reactor 模式包含 Reactor、Acceptor、Handler 三个角色。

- Reactor：负责监听和分配事件。收到事件后分派给对应的 Handler 处理，事件包括连接建立就绪、读就绪、写就绪等。
- Acceptor：负责处理客户端新连接。Reactor 接收到客户端的连接事件后，会转发给 Acceptor，Acceptor 接收客户端的连接，然后创建对应的 Handler，并向 Reactor 注册此 Handler。
- Handler：请求处理器，负责业务逻辑的处理，即业务处理线程。

#### 从技术上看，Reactor 模型一般有三种实现模式。

- 单 Reactor 单线程模型（单 Reactor 单线程）
	- 所有处理逻辑放在单线程中实现，没有上下文切换、线程竞争、进程通信等问题。缺点是在性能与可靠性方面存在比较严重的问题。
- 单 Reactor 多线程模型 （单 Reactor 多线程）
	- 优点是 Handler 收到响应后通过 send 把响应结果返回给客户端，降低 Reactor 的性能开销，提升整个应用的吞吐。而且 Handler 使用多线程模式，可以充分利用 CPU 的性能，提高了业务逻辑的处理速度。
	- 缺点是 Handler 使用多线程模式，带来了多线程竞争资源的开销，同时涉及共享数据的互斥和保护机制，实现比较复杂。另外，单个 Reactor 承担所有事件的监听、分发和响应，对于高并发场景，容易造成性能瓶颈。
- 主从 Reactor 多线程模型 (多 Reactor 多线程)
	-  主线程只负责接收新连接，子线程负责完成后续的业务处理。同时主线程和子线程的交互也很简单，子线程接收主线程的连接后，只管业务处理即可，无须关注主线程，可以直接在子线程把处理结果返回给客户端。所以，主从 Reactor 多线程模型适用于高并发场景，Netty 网络通信框架也采用了这种实现。
**比如 Pulsar、Kafka、RocketMQ，为了保证性能，都是基于主从 Reactor 多线程模型开发的**

#### 基于成熟网络框架提高稳定性并降低开发成本
基于 Java NIO 库开发一个 Server，需要处理网络的闪断、客户端的重复接入、连接管理、安全认证、编解码、心跳保持、半包读写、异常处理等等细节，工作量非常大。所以在消息队列的网络编程模型中，为了提高稳定性或者降低成本，选择现成的、成熟的 NIO 框架是一个更好的方案。

### 主流消息队列的网络模型实现

#### Kafka 网络模型

Processor 线程和 Handler 线程之间通过 RequestChannel 传递数据，RequestChannel 中包含一个 RequestQueue 队列和多个 ResponseQueues 队列。每个 Processor 线程对应一个 ResponseQueue。
![](https://static001.geekbang.org/resource/image/1d/fc/1d7c282b40c75d7c42966a60d35552fc.jpg?wh=3228x1932)
##### 具体流程

1. 一个 Acceptor 接收客户端建立连接的请求，创建 Socket 连接并分配给 Processor 处理。
2. Processor 线程把读取到的请求存入 RequestQueue 中，Handler 线程从 RequestQueue 队列中取出请求进行处理。
3. Handler 线程处理请求产生的响应，会存放到 Processor 对应的 ResponseQueue 中，Processor 线程从其对应的 ResponseQueue 中取出响应信息，并返回给客户端。

#### RocketMQ 网络模型

采用 Netty 组件作为底层通信库，遵循 Reactor 多线程模型，同时又在 Reactor 模型上做了一些扩展和优化。所以它的网络模型是 Netty 的网络模型，Netty 底层采用的是主从 Reactor 多线程模型，模型的原理逻辑跟前面讲到的主从 Reactor 多线程模型是一样的。

![](https://static001.geekbang.org/resource/image/a1/14/a1dd1a870050dc0bb825e28815a51214.jpg?wh=3228x1488)

##### 流程

- 一个 Reactor 主线程负责监听 TCP 网络连接请求，建立好连接，创建 SocketChannel，并注册到 Selector 上。
- RocketMQ 的源码中会自动根据 OS 的类型选择 NIO 和 Epoll，也可以通过参数配置，监听真正的网络数据。
- 接收到网络数据后，会把数据传递给 Reactor 线程池处理。
- 真正执行业务逻辑之前，会进行 SSL 验证、编解码、空闲检查、网络连接管理，这些工作在 Worker 线程池处理（defaultEventExecutorGroup）
- 处理业务操作，放在业务 Processor 线程池中执行。

NIO 编程属于 TCP 层网络编程，我们还需要进行协议设计、编解码、链路的建立 / 关闭等工作，才算完成一个完整的网络模块的开发。有没有更好的方案可以解决这些问题，减少我们的工作量呢？

#### NIO 编程和 RPC 框架
![](https://static001.geekbang.org/resource/image/68/e9/6843dd12f1a5d30636d58d386a99c7e9.jpg?wh=10666x2548)
##### RPC 调用需要的能力
- 网络传输协议：远端调用底层需要经过网络传输，所以需要选择网络通信协议，比如 TCP。
- 应用通信协议：网络传输需要设计好应用层的通信协议，比如 HTTP2 或自定义协议。
- 服务发现：调用的是远端对象，需要可以定位到调用的服务器地址以及调用的具体方法。
- 序列化和反序列化：网络传输的是二进制数据，因此 RPC 框架需要自带序列化和反序列化的能力。

##### RPC 优点

- gRPC 内核已经很好地实现了服务发现、连接管理、编解码器等公共部分，我们可以把开发精力集中在消息队列本身，不需要在网络模块消耗太多精力。
- gRPC 几乎支持所有主流编程语言，开发各个消息队列的 SDK 可以节省很多开发成本。
- 很多云原生系统，比如 Service Mesh 都集成了 gRPC 协议，基于 HTTP2 的 gRPC 的消息队列很容易被云原生系统中的其他组件所访问，组件间的集成成本很低。

> 主流的消息队列都不支持 gRPC 框架，这是因为如果支持就要做很大的架构改动。而且，gRPC 底层默认是七层的 HTTP2 协议，在性能上，可能比直接基于 TCP 协议实现的方式差一些。但是 HTTP2 本身在性能上做了一些优化，从实际表现来看，性能损耗在大部分场景下是可以接受的。
> 
> 所以如果是一个新设计的消息队列或者消息队列的新架构，通过成熟的 RPC 框架来实现网络模块是一个蛮不错的方案。比如 RocketMQ 5.0 中的 Proxy 就使用 gRPC 框架实现了网络模块。

# 地址

此文章为8月day4 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/670965》