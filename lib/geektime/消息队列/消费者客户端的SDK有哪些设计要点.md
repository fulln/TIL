---
dg-publish: true
title: 消费者客户端的SDK有哪些设计要点
createTime: 2023-08-06 17:19  
---
# 消费者客户端的SDK有哪些设计要点

### 消费分组
在没有消费分组直接消费 Topic 的场景下，如果希望不重复消费 Topic 中的数据，那么就需要有一个标识来标识当前的消费情况，比如记录进度。这个唯一标识就是消费分组。

消费分组内有很多个消费者，一个消费分组也可以订阅和消费多个 Topic，一个 Topic 也可以被多个消费分组订阅和消费。

Topic 不存储真实数据，分区才存储消息数据，所以就需要解决消费者和分区的分配关系，即哪个分区被哪个消费者消费，这个分配的过程就叫做消费重平衡（Rebalance）。

新建一个消费分组的时候，就需要开始分配消费者和分区的消费关系了。分配完成后，就可以正常消费。如果消费者和分区出现变动，比如消费者挂掉、新增消费者、订阅的 Topic 的分区数发生变化等等，就会重新开始分配消费关系，否则就会存在某些分区不能被订阅和消费的情况。
![](https://static001.geekbang.org/resource/image/77/52/77e59yy3fc26de63c6f6dea701a75252.jpg?wh=10666x6000)
### 协调者

如果要对消费者和分区进行分配，肯定需要有一个模块拥有消费分组、所有的消费者、分区信息三部分信息，这个模块我们一般命名为协调者。协调者主要的工作就是执行消费重平衡，并记录消费分组的消费进度。

#### 主要工作

1. 在协调者完成，即协调者首先获取消费者和分区的信息，然后在协调者内部完成分区分配，最后再把分配关系同步给所有消费者。
2. 在消费者完成，即负责分配的消费者获取所有消费者和分区的信息，然后该消费者完成分区分配操作，最后再把分配关系同步给其他消费者。

一般在创建消费分组和消费者 / Topic 分区发生变化的时候，会触发协调者执行消费重平衡。
>协调者一般是 Broker 内核的一个模块，就是一段代码或者一个类，专门用来完成上述的工作。当有多台 Broker 时，协调者的实现有多种方式，比如 Kafka 集群每台 Broker 都有协调者存在。通过消费分组的名称计算出来一个 hash 值和 \_\_consumer_offset 的分区数，取余计算得出一个分区号。最后这个分区号对应的 Leader 所在的 Broker 节点就是协调者所在的节点。客户端就和计算出来的这台 Broker 节点进行交互，来执行消费重平衡的相关操作。

#### 消费分区分配策略

##### 分区分配策略的制定一般遵循以下三个原则：

1. 各个分区的数据能均匀地分配给每个消费者，保证所有消费者的负载最大概率是均衡的，该原则最为常用。
2. 在每次重新分配的时候，尽量减少分区和消费者之间的关系变动，这样有助于加快重新分配的速度，并且保持数据处理的连续性，降低处理切换成本。
3. 可以允许灵活地根据业务特性制定分配关系，比如根据机房就近访问最近的分区、某个 Topic 的奇数分区分配给第一个消费者等等。

**所有消息队列的默认策略都是相对通用的，一般都会包含有轮询、粘性、自定义三种类型的策略。**

1. 轮询就是指用轮询的方式将分区分配给各个消费者，保证每个消费者的分区数量是尽量相同的，从而保证消费者的负载最大概率上是均衡的
2. 粘性是指尽量减少分区分配关系的变动，进而减少重平衡所耗费的时间和资源损耗
	1. 为了减少重新分配关系，有一个非常常用的算法是一致性哈希。一致性哈希的算法经常用在负载均衡中。用一致性哈希实现粘性策略的优点是，当节点或者分区变动时，只需要执行少量的分区再分配即可。
	2. 比如 RocketMQ 内部就提供了根据机房就近分配、指定机房分配两种策略，这两种策略的协调者要感知到客户端和服务端的机房信息，然后根据策略进行分配，均主要用在跨可用区场景中
	3. Kafka 也提供了轮询策略改进版 RoundRobinAssignor 分配策略
	4. 自定义分区分配算法

#### 消费确认
当数据被消费成功后，就必须进行消费确认操作了，告诉服务端已经成功消费了这个数据。消费确认就是我们在消息队列中常说的 ACK。

##### 常见形式

1. **确认后删除数据**是指集群的每条消息只能被消费一次，只要数据被消费成功，就会回调服务端的 ACK 接口，服务端就会执行数据删除操作
2. **消费成功保存消费**进度是指当消费数据成功后，调用服务端的消费进度接口来保存消费进度。这种方式一般都是配合消费分组一起用的，服务端从消费分组维度来保存进度数据。

消息队列大多数用的是第二种方案。数据的删除交由数据过期策略去执行。
#### 保存消费进度

当消费端消费完成后，客户端需要调用一个接口提交信息，这个接口是由服务端提供的“提交消费进度”接口，然后服务端会持久保存进度。

![](https://static001.geekbang.org/resource/image/14/da/144495cf3102ce8f56cbf729771a6eda.jpg?wh=10666x3267)

客户端自定义保存是指当消费完成后，客户端自己管理保存消费进度。此时就不需要向服务端接口提交进度信息了，自定义保存进度信息即可，比如保存在客户端的缓存、文件、自定义的服务中，当需要修改和回滚的时候就比较方便。这种方案的优点就是灵活，缺点就是会带来额外的工作量。

#### 消费失败处理

1. 从服务端拉取数据失败，和客户端的错误逻辑处理是一致的，根据可重试错误和不可重试错误的分类，进行重复消费或者向上抛错。
2. 本地业务数据处理失败。
	1. 如果是偶尔失败，那么在业务层做好重试处理逻辑，配合手动提交消费进度的操作即可解决。
	2. 如果是一直失败，即使重试多次也无法被解决，比如这条数据内容有异常，导致无法被处理。此时如果一直重试，就会出现消费卡住的情况，这就需要配合死信队列的功能，将无法被处理的数据投递到死信队列中，从而保存异常数据并保证消费进度不阻塞。
3. 提交位点信息失败，其处理方法通常是一直重试，重复提交，如果持续失败就向上抛错。因为如果提交进度失败，即使再从服务端拉取数据，还是会拉到同一批数据，出现重复消费的问题。


# 地址

此文章为8月day6 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/674123》