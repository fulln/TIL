---
dg-publish: true
title: # 分布式集群的数据一致性
createTime: 2023-08-30 22:43  
---

# 分布式集群的数据一致性

集群中数据的一致性，看看它是如何保证这些分布在多个节点上的副本上的数据是一致的。

### 分区、副本和数据倾斜

为了保证数据写入的顺序性，写入一般都是由 Leader 负责。因为组件功能特性和实现方式的不同， Follower 在功能上一般会分为这样两种情况。

1. 只负责备份。即写入和读取都是在 Leader 完成的，平时 Follower 只负责数据备份。当 Leader 出现异常时，Follower 会提升为 Leader，继续负责读写。
2. 既负责备份也负责读取，不负责写入。即正常情况下，Leader 负责写入，Follower 负责读取和数据备份。当发生异常时，Follower 会提升为 Leader。

在目前消息队列的实现中，一般都是用的第一种方案，即 Master-Slave 的架构。

在具体实现中可以通过增加分区，然后将不同的分区的 Leader 分布在不同的节点上。此时，**我们只要保证每个分区的写入是均匀的，那么就可以避免倾斜问题**

### 副本间数据同步方式

副本之间的同步方式有同步复制和异步复制两种。
1. 同步复制是指主节点接收到数据后，通过同步多写的方式将数据发送到从节点。
2. 异步复制是指主节点接收到数据后，通过主节点异步发送或者从节点异步拉取的方式将数据同步到从节点。

大部分只会实现其中一种方式，比如 Kakfa 是异步复制，Pulsar、RabbitMQ 是同步复制。RocketMQ 是比较特殊的那个，既支持同步复制也支持异步复制。

从数据复制的具体实现上看，一般有通过 Leader 推送 和 Follower 拉取两种方式。
1. Leader 推送是指当 Leader 接收到数据后，将数据发送给其他 Follower 节点，Follower 保存成功后，返回成功的信息给 Leader
2. Follower 拉取是指 Follower 根据一定的策略从 Leader 拉取数据，保存成功后，通知 Leader 数据保存成功。

![](https://static001.geekbang.org/resource/image/85/c2/85319816aa61ddc3340f1ebb6251cec2.jpg?wh=2226x574)


### CAP 和一致性模型

面对的功能业务场景不一样（比如消息和流），此时对一致性和可用性的要求不一样，所以对 AP 和 CP 的支持程度和方式也会不一样。但是为了支持更多的场景，大部分消息队列都会支持更灵活的 AP 和 CP 策略。

消息队列在业务中是用来当缓冲的，起削峰填谷的作用，所以可用性是必须要满足的。消息队列从某种意义上是一个 AP 的系统，但是作为一个存储系统，它又必须保证数据可靠性，所以就会在一致性上想办法。

#### 集群数据一致性和可靠性实现

从技术上看，消息队列作为存储系统，弱一致一般是不考虑的，所以一般是在强一致和最终一致上做选择。但是如果有场景（比如日志）需要弱一致呢？要怎么满足？

>从技术上来看，消息队列都会支持通过配置生效的、灵活的一致性策略。即允许通过修改配置来调整一致性策略，比如在一些需要强一致的场景中，可以通过修改配置来支持强一致。同样的需要最终一致或者弱一致时，也可以通过修改配置来生效。

1. 集群维度固定配置是指在集群部署的时候，就配置好集群的一致性策略，比如 RocketMQ 、Pulsar、ZooKeeper。
2. 用户 / 资源维度灵活配置是指在客户端写入数据的时候或者在 Topic/Queue 维度，可以配置不同的一致性策略，比如 Kafka 和 RabbitMQ。

#### ZooKeeper 数据一致性和可靠性

ZooKeeper 通过主备复制、Epoch 等概念来保证集群中各个副本之间数据的一致性。在 ZooKeeper 中，写入只能在 Leader 完成，Leader 收到数据后会再将数据同步到其他 Follower 节点中，Follower 可以负责读取数据。

>zab 协议本质上是最终一致的协议。它遵循多数原则，即当多数副本保存数据成功后，就认为这条数据保存成功了。多数原则的本质是在一致性和可用性之间做一个权衡，即如果需要全部副本都成功，当底层出现问题时，系统就不可用，而最终一致的可靠性又太弱。所以，多数原则是一个平衡且合理的方案，在业界也是用得最多的。

>而在多数原则理论中，如果数据只写入到 Leader 和 Follower 中，此时这两台节点同时损坏或者集群发生异常时导致 Leader 频繁切换，数据就可能会损坏或丢失。为了解决这些复杂场景，Zab 协议定义了 Zxid、崩溃恢复等细节来保证数据不会丢失。

#### Kafka 数据一致性和可靠性

Kakfa 在分区维度有副本的概念，副本之间通过自定义的 ISR 协议来保证数据一致性。

>kafka 的副本同步是通过 Follower 主动拉取的形式实现的。如下图所示，每台 Follower 节点会维护和 Leader 通信的线程，Follower 会根据一定的策略不停地从 Leader 拉取数据，当数据写入到 Leader 后，Follower 就会拉到对应的数据进行保存。

>如果客户端设置 ACK=-1 表示数据要强一致，数据写入到 Leader，就需要所有 Follower 都**拉取到数据**后，数据才算保存成功。设置 ACK=0 表示弱一致，客户端写入数据后就不管了，不管 Leader 有没有写入成功，Follower 有没有同步。当 ACK=1 表示最终一致，只要 Leader 写入成功后，就认为成功，不管 Follower 有没有同步。

因为 Follower 是可以批量拉取数据的，所以 Kafka 在副本拉取数据的性能上会高许多。在我看来，这个模型的设计是蛮优秀的，通过批量拉取 Leader 数据来提高一致性的性能。但是这个协议存在的缺点是，实现上比较复杂，需要维护副本线程、ACK 超时时间等机制，并且在一些边界场景，比如 Leader 频繁切换的时候，可能会导致分区的数据发生截断，从而导致数据丢失。

为了解决 Leader 切换、数据截断等问题，**Kafka 引入了副本水位、Leader Epoch、数据截断等概念，来保证数据的可用性和可靠性。** 从结果上看，ISR 协议可能存在数据丢失的情况。

在 Kafka 去 ZooKeeper 的版本中，Kakfa 的元数据模块使用基于 Raft 协议实现的 KRaft 来替代 ZooKeeper，从而实现元数据的分布式可靠存储。此时 Kakfa 元数据的一致性和可靠性的实现，其理论基础可以参考 Raft 协议，理论模型都是一致的，只是实现的细节有些不同。

**Kafka 去 ZooKeeper 的版本，其消息数据的数据一致性模型依旧是 ISR 模型**

#### Pulsar 数据一致性和可靠性

Pulsar 是计算存储分离的架构，我们常说的 Pulsar 都是指 Pulsar 的 Broker。Broker 本身是不保存数据的，数据是保存在 BookKeeper 中。所以 Pulsar 的数据一致性协议是配合 BookKeeper 一起完成的。

![](https://static001.geekbang.org/resource/image/d1/52/d18b4e15ac99b74a869d0aeb6f630452.jpg?wh=10666x6000)

数据发送到 Pulsar Broker 中后，Broker 会调用 BookKeeper 的客户端，通过 Ledger 和 Entry 将数据写入到 BookKeeper 中。所以从 Pulsar Broker 的角度来看，**数据的一致性就是通过控制 Ledger 数量和 Ledger 在 BookKeeper 上的分布来实现的。**

Pulsar 副本间的数据同步方式是 Leader 收到数据后，主动写入到多个 Ledger 的。Leader 会等到配置的 Qa 数量的副本写入成功，才告诉客户端写入成功。

Pulsar 副本间的数据同步方式是 Leader 收到数据后，主动写入到多个 Ledger 的。Leader 会等到配置的 Qa 数量的副本写入成功，才告诉客户端写入成功。Broker 和 BookKeeper 之间是以流的方式写入数据的，即会先创建一个 Ledger，然后将消息包装为一个一个的 Entry，然后通过流的方式写入到 Ledger 中。**流方式的写入可以提高写入的性能。**

# 地址

此文章为8月day30 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/681965》