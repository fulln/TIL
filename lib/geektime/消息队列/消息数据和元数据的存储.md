---
dg-publish: true
title: 消息数据和元数据的存储
createTime: 2023-07-27 23:37  
---

## 存储模块的功能设计和实现。

消息队列中的数据一般分为元数据和消息数据。元数据是指 Topic、Group、User、ACL、Config 等集群维度的资源数据信息，消息数据指客户端写入的用户的业务数据。下面我们先来看元数据信息的存储。

### 元数据信息的存储
不会经常读写，但是需要保证数据的强一致和高可靠，不允许出现数据的丢失

元数据信息一般需要通知到所有的 Broker 节点，Broker 会根据元数据信息执行具体的逻辑。比如创建 Topic 并生成元数据后，就需要通知对应的 Broker 执行创建分区、创建目录等操作。

#### 基于第三方组件来实现元数据的存储是目前业界的主流选择

最大的优点是集成方便，开发成本低，能满足消息队列功能层面的基本要求，因为我们可以直接复用第三方组件已经实现的一致性存储、高性能的读写和存储、Hook 机制等能力，而且在后续集群构建中也可以复用这个组件，能极大降低开发难度和工作成本

引入第三方组件会增加系统部署和运维的复杂度，而且第三方组件自身的稳定性问题会增加系统风险，第三方组件和多台 Broker 之间可能会出现数据信息不一致的情况，导致读写异常。

#### 集群内部实现元数据的存储是指在集群内部完成元数据的存储和分发。

基于 Raft 协议实现内部的元数据存储模块或依赖一些内置的数据库。目前 Kafka 去 ZooKeeper 的版本、RabbitMQ 的 Mnesia、Kafka 的 C++ 版本 RedPanda 用的就是这个思路。


消息队列核心架构已成熟或者前期允许有较大投入，我才会建议你选择第二种方案。因为第一种方案虽然开发成本较低，但其使用成本、机器资源成本、运维成本还是偏高，另外，一些稳定性问题，比如元数据不一致，因为第三方组件的存在是无法根治的，会有长久的隐患。

### 消息数据的存储

1. 数据存储结构设计
Topic 和 Group 不承担数据存储功能，承担的是逻辑组织的功能，实际的数据存储是在在分区维度完成的。

数据的落盘存储也有两个思路。
- 每个分区单独一个存储“文件”。

每个分区上的数据顺序写到同一个磁盘文件中，数据的存储是连续的。因为消息队列在大部分情况下的读写是有序的，所以这种机制在读写性能上的表现是最高的。

- 每个节点上所有分区的数据都存储在同一个“文件”。

每个节点上所有分区的数据都存储在同一个文件中，这种方案需要为每个分区维护一个对应的索引文件，索引文件里会记录每条消息在 File 里面的位置信息，以便快速定位到具体的消息内容。

所有文件都在一份文件上，管理简单，也不会占用过多的系统 FD 资源，单机上的数据写入都是顺序的，写入的性能会很高

假设这个统一的文件叫 commitlog，则 commitlog 就是用来存储数据的文件，.index 是每个分区的索引信息。


#### 核心考虑是你对读和写的性能要求

1. 第一种方案，单个文件读和写都是顺序的，性能最高。但是当文件很多且都有读写的场景下，硬盘层面就会退化为随机读写，性能会严重下降。
2. 第二种方案，因为只有一个文件，不存在文件过多的情况，写入层面一直都会是顺序的，性能一直很高。但是在消费的时候，因为多个分区数据存储在同一个文件中，同一个分区的数据在底层存储上是不连续的，硬盘层面会出现随机读的情况，导致读取的性能降低。

### 消息数据的分段实现

如果进行了分段，消息数据可能分布在不同的文件中。所以我们在读取数据的时候，就需要先定位消息数据在哪个文件中。为了满足这个需求，技术上一般有根据偏移量定位或根据索引定位两种思路。

1. 根据偏移量（Offset）来定位消息在哪个分段文件中，
> 是指通过记录每个数据段文件的起始偏移量、中止偏移量、消息的偏移量信息，来快速定位消息在哪个文件。当消息数据存储时，通常会用一个自增的数值型数据（比如 Long）来表示这条数据在分区或 commitlog 中的位置，这个值就是消息的偏移量。

2. 用索引定位
> 通过维护一个单独的索引文件，记录消息在哪个文件和文件的哪个位置。读取消息的时候，先根据消息 ID 找到存储的信息，然后找到对应的文件和位置，读取数据。RabbitMQ 和 RocketMQ 用的就是这个思路。





# 地址 

此文章为7月day27 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/671725》