---
dg-publish: true
title: # 构建分布式的消息队列集群
createTime: 2023-08-29 22:36  
---
# 构建分布式的消息队列集群

### 元数据存储服务的设计选型

业界主要有基于第三方存储引擎和集群内部自实现元数据存储两种方案。我们先来分析一下这两种方案的具体实现。

#### 1. 基于第三方存储引擎
一般只要具备可靠存储能力的组件都可以当作第三方引擎。简单的可以是单机维度的内存、文件，或者单机维度的数据库、KV 存储，进一步可以是分布式的协调服务 ZooKeeper、etcd 等等。

Controller 和 Metadata Service 是分开的，各自承担着不同的职能。

Controller 是无状态的，因为它不负责保存数据，只负责计算逻辑。所以在这种情况下，一般就会让集群中的某台 Broker 来承担 Controller 的功能。当这台 Broker 挂了后，可以依赖元数据存储服务把 Controller 切换到新的 Broker。因为它是无状态的，所以切换是非常快的。
#### 2. 集群内部自实现元数据存储

如何实现：

1. 直接在 Broker 内部构建一个小型的元数据存储集群来提供服务。
2. 通过某些可以内嵌到进程的小型的分布式存储服务来完成元数据的存储。
3. 通过某些可以内置的单机持久化的服务，配合节点间的元数据同步机制来完成元数据的存储。

>元数据集群和 Broker 集群最大的差别在于它只需要承担单个集群的元数据管理存储，数据量和规模很小，集群一般不需要扩容。所以这个集群适合使用“通过配置发现节点的方案”来构建集群。Kafka 的 KRaft 架构用的就是这种方案。

>第二种方案是利用某种可以内嵌到进程的存储服务来存储元数据，比如 Mnesia 或 RocksDB。如果是单机的存储引擎，比如 RocksDB，那么主要适用于单机部署的场景。单机存储引擎的方案如果要实现元数据的集群化，那么就得在节点之间实现相互同步数据的机制，这个就相对复杂许多。而如果是分布式的存储引擎，如 Mnesia，那么就简单许多，几乎没有工作量，直接调用存储引擎的接口存储元数据即可。

>第三种方案是在节点上部署一个持久化的单机存储引擎，如 RocksDB 等。然后在 Broker 内维护节点间的元数据数据的一致性。这种方式也是一种实现比较简单的方案，开发难度低于第一种方案，高于第二种方案。

### ZooKeeper 的集群构建

ZooKeeper 是一个分布式的数据协调服务，本质上是一个简单的、分布式、可靠的数据存储服务。核心操作就是数据的写入、分发、读取和 Hook。从客户端看，主要操作就是写入和读取。从服务端看，主要操作就是集群构建、数据接收、存储、分发和 Hook。

它会事先在配置中定义好集群中所有节点的 IP 列表。然后集群启动时，会在这些节点之间进行选举，经过多数投票机制，选举出一个 Leader 节点，从而构建成为集群。

>ZooKeeper 只是一个数据存储服务，并没有很多管控操作，Leader 节点就负责数据的写入和分发，Follower 不负责写入，只负责数据的读取。当 Leader 收到操作请求时，比如创建节点、删除节点、修改内容、修改权限等等，会保存数据并分发到多个 Follower，当集群中有一半的 Follower 返回成功后，数据就保存成功了。当 Follower 收到写入请求时，就把写入请求转发给 Leader 节点进行处理。

### Kafka 的集群构建

1. 基于 ZooKeeper 的集群
Broker 在启动或重连时，会根据配置中的 ZooKeeper 地址找到集群对应的 ZooKeeper 集群。然后会在 ZooKeeper 的 /broker/ids 目录中创建名称为自身 BrokerID 的临时节点，同时在节点中保存自身的 Broker IP 和 ID 等信息。当 Broker 宕机或异常时，TCP 连接就会断开或者超时，此时临时节点就会被删除。

2. 



# 地址

此文章为8月day29 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/680879》