---
dg-publish: true
title: 拆解Kafka的架构设计与实现
createTime: 2023-08-09 21:21  
---

# 拆解Kafka的架构设计与实现

### Kafka 系统架构

Kafka 由 Producer、Broker、ZooKeeper、Consumer 四个模块组成。其中，ZooKeeper 用来存储元数据信息，集群中所有元数据都持久化存储在 ZooKeeper 当中。

![](https://static001.geekbang.org/resource/image/39/5a/39d54678ca944b19d2470521dfbec15a.jpg?wh=10666x5048)

从消息的生命周期来看，生产者也需要通过客户端寻址拿到元数据信息。客户端通过生产分区分配机制，选择消息发送到哪个分区，然后根据元数据信息拿到分区 Leader 所在的节点，最后将数据发送到 Broker。Broker 收到消息并持久化存储。消费端使用消费分组或直连分区的机制去消费数据，如果使用消费分组，就会经过消费者和分区的分配流程，消费到消息后，最后向服务端提交 Offset 记录消费进度，用来避免重复消费。

#### 协议和网络模块

Kafka 是自定义的私有协议，经过多年发展目前有 V0、V1、V2 三个版本，稳定在 V2 版本。官方没有支持其他的协议，比如 HTTP，但是商业化的 Kafka 一般都会支持 HTTP 协议，原因还是 HTTP 协议使用的便捷性。

**协议头包含基础通用的信息，协议体由于每个接口的功能参数不一样**，内容结构上差异很大。

#### 数据存储

##### 元数据存储

Kafka 的元数据是存储在 ZooKeeper 里面的。元数据信息包括 Topic、分区、Broker 节点、配置等信息。ZooKeeper 会持久化存储全量元数据信息，Broker 本身不存储任何集群相关的元数据信息。在 Broker 启动的时候，需要连接 ZooKeeper 读取全量元数据信息。

>从 ZooKeeper 的角度来看，Kafka 只是它的一个使用者，Kafka 用 ZooKeeper 的标准使用方式向 ZooKeeper 集群上写入、删除、更新数据，以完成 Kafka 的元数据管理、集群构建等工作。所以每台 Broker 启动时，都会在 ZooKeeper 注册、监听一些节点信息，从而感知集群的变化。

Kakfa 集群中的一些如消费进度信息、事务信息，分层存储元数据，以及 3.0 后的 Raft 架构相关的元数据信息，都是基于内置 Topic 来完成存储的。

![](https://static001.geekbang.org/resource/image/62/46/6260ced9bbb35d3c9fc9185314df2d46.jpg?wh=10666x3829)

##### 消息数据
当 Broker 收到数据后，是直接将数据写入到不同的分区文件中的。所以在消费的时候，消费者也是直接从每个分区读取数据。
![](https://static001.geekbang.org/resource/image/ff/82/ffd5d608f6ffc0a2f506d098ba7f7782.jpg?wh=10666x3689)

>每个分区的目录下，都会有 .index、.log、.timeindex 三类文件。其中，.log 是消息数据的存储文件，.index 是偏移量（offset）索引文件，.timeindex 是时间戳索引文件。两个索引文件分别根据 Offset 和时间来检索数据。

>每个分区存储的数据量会很大，分区数据也会进行分段存储。分段是在.log 进行的，文件分段的默认数据大小也是 1G，可以通过配置项来修改。


**Kafka 提供了根据过期时间和数据大小清理的机制，清理机制是在 Topic 维度生效的。** 当数据超过配置的过期时间或者超过大小的限制之后，就会进行清理。清理的机制也是延时清理的机制，它是根据每个段文件进行清理的，即整个文件的数据都过期后，才会清理数据。

 > 根据大小清理的机制是在分区维度生效的，不是 Topic。即当分区的数据大小超过设置的大小，就会触发清理逻辑。这个机制和 RocketMQ 的清理机制是一致的，但 RocketMQ 只提供了按节点维度配置的消息过期机制，所以相比之下，根据分区维度存储能带来一定的便捷。

在存储性能上，Kafka 的写入大量依赖顺序写、写缓存、批量写来提高性能。消费方面依赖批量读、顺序读、读缓存的热数据、零拷贝来提高性能。在这些技巧中，每个分区的顺序读写是高性能的核心。

#### 生产者和消费者

Kafka 客户端在连接 Broker 之前需要经过客户端寻址，找到目标 Broker 的信息。在早期，Kafka 客户端是通过链接 ZooKeeper 完成寻址操作的，但是因为 ZooKeeper 的性能不够，如果大量的客户端都访问 ZooKeeper，那么就会导致 ZooKeeper 超载，从而导致集群异常。

##### 生产者

生产者完成寻址后，在发送的时候可以将数据发送到 Topic 或者直接发送到分区。发送到 Topic 时会经过生产分区分配的流程，即根据一定的策略将数据发送到不同的分区。

**Kafka 提供了轮询和 KeyHash 两种策略。**
>轮询策略是指按消息维度轮询，将数据平均分配到多个分区。Key Hash 是指根据消息的 Key 生成一个 Hash 值，然后和分区数量进行取余操作，得到的结果可以确定要将数据发送到哪个分区。生产消息分配的过程是在客户端完成的。

>Kafka 协议提供了批量（Batch）发送的语义。所以生产端会在本地先缓存数据，根据不同的分区聚合数据后，再根据一定的策略批量将数据写入到 Broker。因为这个 Batch 机制的存在，客户端和服务端的吞吐性能会提高很多。

客户端批量往服务端写有两种形式：
一种是协议和内核就提供了 Batch 语义，
一种是在业务层将一批数据聚合成一次数据发送。

这两种虽然都是批量发送，但是它们的区别在于：

第一种批量消息中的每条消息都会有一个 Offset，每条消息在 Broker 看来就是一条消息。第二种批量消息是这批消息就是一条消息，只有一个 Offset。
在消费端看来，第一种对客户端是无感的，一条消息就是一条消息。第二种需要消费者感知生产的批量消息，然后解析批量，逐条处理。

#### 消费者

Kafka 的消费端只提供了 Pull（拉）模式的消费。即客户端是主动不断地去服务端轮询数据、获取数据，消费则是直接从分区拉取数据的。Kafka 提供了消费分组消费和直连分区消费两种模式，这两者的区别在于，是否需要进行消费者和分区的分配，以及消费进度谁来保存。

大部分情况下，都是基于消费分组消费。消费分组创建、消费者或分区变动的时候会进行重平衡，重新分配消费关系。**Kafka 默认提供了 RangeAssignor（范围）、RoundRobinAssignor（轮询）、 StickyAssignor（粘性）三种策略**，也可以自定义策略。消费分组模式下，一个分区只能给一个消费者消费，消费是顺序的。

当客户端成功消费数据后，会往服务端提交消费进度信息，此时服务端也不会删除具体的消息数据，只会保存消费位点信息。位点数据保存在内部的一个 Topic（\_\_consumer_offset）中。消费端同样提供了自动提交和手动提交两种模式。当消费者重新启动时，会根据上一次保存的位点去消费数据，用来避免重复消费。


#### HTTP 协议支持和管控操作

Kafka 内核是不支持 HTTP 协议的，如果需要支持，则需要在 Broker 前面挂一层代理。如 Confluent 开源的 Kafka Rest。

管控的大部分操作是通过 Kafka Protocol 暴露的，基于四层的 TCP 进行通信。还有部分可以通过直连 ZooKeeper 完成管控操作。

在早期很多管控操作都是通过操作 ZooKeeper 完成的。后来为了避免对 ZooKeeper 造成压力，所有的管控操作都会通过 Broker 再封装一次，即客户端 SDK 通过 Kafka Protocol 调用 Broker，Broker 再去和 ZooKeeper 交互。


## 总结

1. 协议层只支持私有的 Kafka Protocol 协议。
2. 网络层是基于原生的 Java NIO 开发，底层也是通过多路复用、异步 IO、Reactor 模型等技术来提高网络模块的性能。
3. 存储层是每个分区对应一份具体的存储文件，分区文件在底层会分段存储，同时支持基于时间和大小的数据过期机制。
4. 元数据存储是通过 ZooKeeper 来实现的，所有的元数据都存储在 ZooKeeper 中。
5. 客户端的访问同样也需要经过客户端寻址机制。老版本可以通过 ZooKeeper 获取元数据信息，新版本只能通过 Broker 拿到元数据信息。拿到所有元数据信息后，才会直连 Broker。
6. 生产端支持将数据写入到 Topic 或指定写入某个分区，写入 Topic 时需要经过生产分区分配操作，选择出最终需要写入的分区，同时支持批量写入的语义。
7. 消费端也有消费分组的概念，消费时需要在多个消费者和消费分组之间进行消费的负载均衡，同时也支持指定分区消费的模式。
# 地址

此文章为8月day9 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/675914》