---
dg-publish: true
title: 消息不丢失
createTime: 2023-08-16 22:28  
---
# 生产者收到写入成功响应后消息一定不会丢失吗？

从生产者发出，到消费者完成消费，每一个环节都需要考虑什么才可以确保自己的消息不会丢失。到最后，我会再给你一个在 Kafka 的基础上支持消息回查的方案，帮助你在面试的时候赢得竞争优势。让我们先从基础知识开始。

### Kafka 主从同步与 ISR

为了避免分区所在的消息服务器宕机，分区本身也是一个主从结构。换一句话来说，不同的分区之间是一个对等的结构，而每一个分区其实是由一个主分区和若干个从分区组成的。

不管是主分区还是从分区，都放在 broker 上。但是在放某个 topic 分区的时候，尽量做到一个 broker 上只放一个主分区，但是可以放别的主分区的从分区。

#### 写入语义

它让生产者来决定写入语义。这个控制参数叫做 acks，它的取值有三个。

- 0：就是所谓的 “fire and forget”，意思就是发送之后就不管了，也就是说 broker 是否收到，收到之后是否持久化，是否进行了主从同步，全都不管。
- 1：当主分区写入成功的时候，就认为已经发送成功了。
- all：不仅写入了主分区，还同步给了所有 ISR 成员。

#### ISR

ISR（In-Sync Replicas）是指和主分区保持了主从同步的所有从分区。比如说，一个主分区本身有 3 个从分区，但是因为网络之类的问题，导致其中一个从分区和主分区失去了联系，没办法同步数据，那么对于这个主分区来说，它的 ISR 就是剩下的 2 个分区。

### 消息丢失的各种场景


#### 生产者发送
生产者能够拿到消息客户端返回的成功响应，但是事实上 broker 可能根本没收到，或者收到了但是处理新消息的时候遇到 Bug 了

#### 主从同步

在 acks=1 的时候，只要求写入主分区就可以。所以假设在写入主分区之后，主分区所在 broker 立刻就崩溃了。这个时候发起新的主分区选举，不管是哪个从分区被选上，它都缺了这条消息。

#### 刷盘

>当 acks=1 的时候，主分区返回写入成功的消息，但是这个时候消息可能还在操作系统的 page cache 里面。而当 acks=all 的时候，主分区返回写入成功的消息，不管是主分区还是 ISR 中的从分区，这条消息都可能还在 page cache 里面。

Kafka 中，控制刷盘的参数有三个。

1. log.flush.interval.messages：控制消息到多少条就要强制刷新磁盘。Kafka 会在写入 page cache 的时候顺便检测一下。
2. log.flush.interval.ms：间隔多少毫秒就刷新数据到磁盘上。
3. log.flush.scheduler.interval.ms：间隔多少毫秒，就检测数据是否需要刷新到磁盘上。
### 消费者提交

消费者提交是指消费者提交了偏移量，但是最终却没有消费的情况。比如说线程池形态的异步消费，消费者线程拿到消息就直接提交，然后再转交给工作线程。在转交之前，或者工作线程正在处理的时候，消费者都有可能宕机。于是一个消息本来并没有被消费，但是却被提交了，这也叫做消息丢失。

## 面试总结
### 保证消息的可靠性

##### 发送方一定发了消息
1. 大体上有两种方案：本地消息表和消息回查。
> 在业务操作的过程中，在本地消息表里面记录一条待发消息，做成一个本地数据库事务。然后尝试立刻发送消息，如果发送成功，那么就把本地消息表里对应的数据删除，或者把状态标记成已发送。

最后提到的异步补发机制，找到需要发送但是又没有发送的消息发送出去。更直观的来说，就是这个线程会执行一个类似这样的 SQL。
![](https://static001.geekbang.org/resource/image/d8/86/d8d681ff7bc0469aa703d80bc2481f86.png?wh=1844x1414)


1. 如果已经提交事务了，那么即便服务器立刻宕机了也没关系。因为我们的异步补发机制会找出这条消息，进行补发。 
2. 如果消息发送成功了，但是还没把数据库里的消息状态更新成已发送，也没关系，异步补发机制还是会找出这条消息，再发一次。也就是说，在这种情况下会发送两次。 
3. 如果在重试的过程中，重发成功了但是还没把消息状态更新成已发送，和第 2 点一样，也是依赖于异步补发机制。
在你的本地消息表里，还可以用额外的字段来控制重试间隔和重试次数。

>一个是消息体列，里面存储了消息的数据；另一个是重试机制列，里面可以只存储重试次数，也可以存储重试间隔、已重试次数、最大重试次数。剩余的列，你就根据自己的需要随便加，不关键。

#### 消息队列不丢失

发送者一定发了消息就意味着它拿到了消息队列的响应，那么根据前面的基础知识，要想让消息队列一定不会丢失消息，那么 acks 就需要设置成 all。而且，也不能允许 Kafka 使用 unclean 选举。考虑刷盘的问题.

当消息队列确保消息不会丢失之后，你需要做的就是确保消费者肯定消费了。

#### 消费者肯定消费

> 要确保消费者肯定消费消息，大多数时候都不需要额外做什么，但是如果业务上有使用异步消费机制就要小心一些。比如说我的 A 业务里面就采用了异步消费来提高消费速率，我利用批量消费、批量提交来保证异步消费的同时，也不会出现未消费的问题。

##### 在 Kafka 上支持消息回查机制

###### 回查实现

它的基本步骤是这样的：
1. 应用代码把准备消息发送到 topic=look_back_msg 上。里面包含业务 topic、消息体、业务类型、业务 ID、准备状态、回查接口。
2. 回查中间件消费这个 look_back_msg，把消息内容存储到数据库里。
3. 应用代码执行完业务操作之后，再发送一个消息到 look_back_msg 上，带上业务类型、业务 ID 和提交状态这些信息。如果应用代码执行业务出错了，那么就使用回滚状态。
4. 回查中间件查询消息内容，转发到业务 topic 上。

> 如果在业务操作完成之后，没有发提交消息，这时候就需要回查中间件来回查。一般来说，回查中间件会异步地扫描长时间未提交的消息，然后回查业务方。

> 业务方需要提供回查 URL。而对于 RPC 调用来说，业务方需要实现我提供的回查接口，然后提供对应的服务名。我在回查的时候会带上业务类型和业务 ID，业务方需要告诉我这个消息能不能提交，也就是要不要发给业务 topic。

>回查中间件得知道怎么回查你的应用代码。正常来说，你这里应该要设计成可扩展的，也就是说可以回查 HTTP 接口，也可以回查 RPC 接口。

###### 2. 数据存储

>为了保证我这个回查机制的高性能和高可靠，我使用了分区表。我按照时间进行分区，并且历史分区是可以快速归档的，毕竟这个回查机制使用的数据库只是临时存储一下消息数据而已。当然，后续随着业务扩展，我觉得这个地方是可以考虑使用分库分表的，比如说按照业务 topic 来分库分表。

###### 3. 有序消息
> 要求准备消息和提交消息是有序的，也就是说，同一个业务的准备消息一定要先于提交消息。解决方案也很简单，在发送的时候要求业务方按照业务 ID 计算一个哈希值，然后除以分区数量的余数，就是目标分区。


# 地址
 
此文章为8月day16 学习笔记，内容来源于极客时间《https://time.geekbang.org/column/article/687062》