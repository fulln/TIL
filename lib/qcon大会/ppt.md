 --- 

# 系统稳定性之我见
## Qcon大会总结

#### 李锋
#### 快递业务处


---
# 关于QCon

<iframe height=1000 width=90% src="https://qcon.infoq.cn/202309/beijing/" frameborder=0 allowfullscreen ></iframe>


---
<grid drag="40 30" drop="topleft">
# 目录
</grid>

<style>
	.menu {
		  font-size:45px;
	}
</style>

<div class= 'menu'>

- **应用流量调度**
- 微服务可用性工具
- 核心微服务架构
- Kafka
- 混沌工程

</div>

---
<grid drag="50 10" drop="topleft">
## 打造流量调度平台
</grid>

![[Pasted image 20230710112143.png]]

---

## DNS

<split even gap="3">

自建+云解析混合同时使用

自有IDC作为DNS后台，写入master，同步到各个云服务,云上弹性资源部署slave节点
![[Pasted image 20230710112509.png]]

统一域名管理入口
![[Pasted image 20230709224049.png]]

</split>

---

## 7层负载均衡

1. 核心功能多云一致性，遵循统一规范 
2. 易于扩展，生效快速 
3. 基础功能符合开源标准，能与内部系统打通

---

## APISIX

![[Pasted image 20230731030306.png]]

---
<grid  drag="40 20" drop="top" >
## 负载均衡部署
</grid>

<grid  drop="left" >
![[Pasted image 20230530231703.png]]
</grid>

<grid  drop="right">
1. 使用[APISIX](https://apisix.apache.org/zh/) + 参与领导社区建设
2. 利用ApiSix插件功能,连接prometheus,SkyWalking等现有插件
3. 域名维度配置全量增量更新，多云同步一致
4. 集群均分流量，网络，集群异常通过DNS屏蔽
5. 通过标签信息，在进行负载均衡前，将节点过滤
6. 单个指令操作，集群级快速生效，不需要逐个域名进行配置，秒级快速生效
</grid>

---
<grid drag="40 30" drop="topleft">
# 目录
</grid>

<style>
	.menu {
		  font-size:45px;
	}
</style>

<div class= 'menu'  >

- 应用流量调度
- **微服务可用性工具**
- 核心微服务架构
- Kafka
- 混沌工程

</div>

---
## 菜鸟单笔高可用体系建设大图

![[Pasted image 20230710114445.png]]

---
<grid  drop="top" drag="100" >

## 统一的结构化日志

_事件、用户身份、系统表现、错误码，业务单号，单据状态_

</grid>


<grid drop="left" style="font-size:16px" drop= "5 10">

> [!info] 正常日志格式 
> 时间戳->业务场景->是否成功->耗时->错误码->错误信息->请求id->调用序号
> timestamp->eventCode->success->rt->errorCode->errorMsg->traceId->rpcId

> [!ERROR] 异常日志格式
> 时间戳->异常类->异常方法->异常行号->错误码->错误信息->请求id->堆栈
> timestamp->clazz->method->lineNumber->errorCode->errorMsg->traceId-> exceptionStack
</grid>

<grid  drop="right" drag= "40 50" bg="white" opacity="0.5" flow="col" >

| 日志场景     | 日志名称     |
| ------------ | ------------ |
| 场景入口日志 | entrance.log |
| 出入参日志   | biz.log      |
| 下游调用日志 | event.log    |
| 异常日志     | error.log    |

</grid>

---


<grid  drag="60 100" drop="center" bg="coral" flow="col">
## 单笔全链路查询排查

_根据标准的日志结构,搭建全链路排查能力_

![[Pasted image 20230731232243.png]]

1. 调用链路（一次完整RPC调用，traceId唯一）

2. 业务全链路（多次RPC调用，业务单号唯一）

</grid>

---



## 2. 单笔全链路查询排查
根据标准的日志结构,搭建全链路排查平台
	1. 调用链路（一次完整RPC调用，traceId唯一）
	2. 业务全链路（多次RPC调用，业务单号唯一）
		1.  单据实体 (事件,业务,规则)

#### 3. 主动识别单笔异常
![[Pasted image 20230710115300.png]]
1. 指标监控（流量、错误、延时、饱和度等）
2. 卡单监控
3. 上下游数据一致性监控	

##### 上下游数据一致性

> binlog同步 -> 落库hbase -> 数据校验.

单日百亿条数据，验证上下游的数据一致性。

##### 重试平台
![[Pasted image 20230530004259.png]]

#### 4. 真实，无损的单笔异常注入
系统服务，容器、宿主机、网络、机房等基础设施，卡单异常注入，单据数据篡改

##### 产业互联网中混沌工程常见挑战：
1. 异常的注入不够真实
2. 真实异常不敢注入

##### 菜鸟使用的方式：
1. 数据旁路篡改，看一致性校验监控中是否得以发现
2. 构建测试流量

> 接下来我们看下美团中针对**核心服务**是如何进行做业务功能稳定性的优化的
### 美团履约平台调度引擎架构

#### 业务的定位特点
- 线上+线下履约过程的最后一环
- 保障商家，用户，骑士的体验
- 时效性强
- 稳定性要求极高

#### 稳定性优化

##### 1. 数据内容的拆分
	1. 实时数据
		1. 可以水平拆分
		2. 业务数据变化频繁,对数据变化敏感
	2. 离线数据
		1. TB级别数据
		2. 难拆分
		3. 数据按照天维度更新

##### 2. 有状态服务
以城市维度进行服务的划分

1. 容量稳定侧,路由需要额外成本
	1. 做更细粒度容量管理,如城市维度
2. 状态重建难度大,需要缩短发布时间
	1. 发布
		1. 恢复状态,降低影响
	2. 弹性伸缩
		1. 状态迁移,使用数据快照
3. 状态存储溢出
	1. 设置内存容量上限,超过只落磁盘
	2. 牺牲读,降级读磁盘
	3. 分片迁移其他副本
	4. 自动恢复
4. 数据一致性
	1. 实时同步
	2. 分钟级检查修复
		1. 补数据
		2. 告警,检查问题产生原因

> 关注完应用端，我们关注下阿里云在**中间件**稳定性上做的内容
### 微服务架构探索

#### 1. 异地多活
同城容灾到异地中心容灾要保证
	- 流量切换
	- 数据不丢
	- 数据一直

![[Pasted image 20230710011123.png]]

如果选择异地冷备，容易出现 
	- 流量未验证
	- 成本高

所以一般采用争先容灾:
 - 强中心应用,需要跨单元调用
 - 正常交易运行时:
	 - 中心75%
	 - 容灾机房 25%，其中强中心应用1%
- 容灾态:
	- 容灾机房:100 %

#### 2. 规模化后内核稳定性问题

要面向千万级微服务构建稳定的最小核心微服务内核

##### 1. dubbo接口注册导致问题
	1. 推送效率低
	2. 业务端内存占比高
	3. 地址信息大
解决办法 
1. 减少rpc的地址信息
	1. 只保留地址信息，地址发现聚合key
	2. 地址中心同步内容仅包括地址ip元数据
	3. 其他元数据在provider，存入MetaDataService
		1. consumer 感应md5,直接从producer直接去拉去配置
		2. 暴露更多治理数据
2. 新老业务兼容
	1. 双注册模式
		1. 接口+ 应用

##### 2. 注册中心同步的问题
	1. 稳定性问题。单点存储256G达到上限；网卡易打
	爆。
	2. 推送效率问题。集群间双写，实时性O(n^2)。单节
	点pub，客户端全量 sub。
	1. 一致性问题。
解决方案：
1. Session和Data分离，Data分片；流量过载保护；推送控制；请求拒绝策略。
2. 数据压缩（1:30）；合并推送请求；增量推送。
3. 最终一致性；推空保护。

#### 3. 一致性问题

SEATA 分布式事务

#### 4. 微服务的互联互通

1. 南北流量做到跨平台跨语言
	1. http协议
	2. 网关转换
		1. 性能低
		2. 转换有损,丢标
	3. 性能/扩展性高
2. dubbo 暴露多协议（grpc，rest）
![[Pasted image 20230710013659.png]]

> 接下来看下腾讯云**kafka**的降本增效
### kafka稳定性与降本增效

**kafka常见问题** 
1. 节点,硬盘成本占比较高
2. 常见稳定性问题
	1. 客户端超时 
	2. 生产写入失败
	3. 生产写入慢
	4. 消费堆积
	5. 硬盘打满
	6. CPU打满 & GC严重 
	7. 节点、机房、可用区故障

#### 1.  通过弹性计算架构提供稳定性

##### 有状态kafka服务计算 => 无状态计算

1. 尽量迁移少量的老数据 => 【分层存储】
	1. 冷热数据分离
2. 计算存储分离，弹性的计算层
	1. 方案1 快速挂载
		1. 完全不管原数据
	2. 方案2 使用分布式文件系统
		1. 有部分同步的问题
	3. 方案3 计算存储分离架构
		1. proxy方案
			1. 内核不用改动
		2. 底层存储切换远端引擎
		3. 内核支持
			1. 方案改动大, 对现有系统不友好,如阿里云盘古

最终腾讯云选择方案2+扩展

##### 弹性本地存储

- 云盘+ 运营调度系统
	- 目标是发现快速发现需要扩容or缩容
- 多云盘+ 多目录
	- 数据倾斜的问题要通过调度系统处理

![[Pasted image 20230710015757.png]]

通过更加廉价的存储，让kafka开启分层存储，开启分层存储后,先写本地在写远端,消费也要从远端拉取数据,读到本地.

#### 2. 集群自均衡(Self Rebalance)防止数据倾斜

**针对rebalance条件限制：
1. 校验Leader切换的影响 
2. 低峰执行均衡 
3. 均衡前的严格校验，如流量、网络限制 
4. 均衡对象的选择，比如白名单、黑名单

> 接下来是字节**混沌工程**的实践
### 可观测混沌工程

![[Pasted image 20230710105057.png]]

#### 混沌工程主要遇到的痛点问题和解决手段
	- 演练前，实验设计无从下手
		- 需要梳理自身架构
		- 演练薄弱环节
	- 演练中，故障效果难以观测
		- 需要做到 集群接入 -> 拓扑感知 ->依赖感知 -> 可视化演练
		- 故障执行受到机器环境干扰
		- 底层故障生效了，但是业务侧感知不到，需要有个可观测实现，根据不同类型进行观测
			- 指标采集
			- 文本采集
			- 第三方的监控接入
	- 演练后，结果难以衡量
		- 需要围绕实验前的稳态和实验后的稳态来衡量效果
			- 如cpu，qps，http返回码等

> 接下来是腾讯**系统安全**的相关介绍
### 零信任安全架构实践

#### 1. 传统边界防护的挑战
1. 内网边界突破
2. 数字化转型挑战
3. 割裂的安全管理
4. 业务上云缺乏管控

#### 2. 零信任实践
员工可以在任意地点,使用任意设备,软件应用,安全访问内网资源办公

##### 设计思路:
持续评估,检查安全状态
- 可信身份
	- 动态口令
		- token
		- 扫码
- 可信终端
	- 对设备进行保护
	- 病毒检测和合规检测信息收集
- 可信软件
	- 黑白灰等不同软件控制,在终端上进行流量劫持
		- 访问的时候检查进程,hash
- 可信链路(防止网关暴露的任意网络)
	- 链路加密
	- 系统应用代理
	- 虚拟网卡
	- 网络驱动

## 总结

**稳定性优先下的成本优化策略
1. 稳定性 > 成本
2. 集群粒度差异化的成本优化策略。 
3. 更细致的运营调度分析体系，让时间差带来的价值。
4. 架构升级提升软件性能、按量付费、丰富产品特性 => 置换成本优化后SLA

**微服务大规模演进的思考** 

1. 稳定性。稳定性永远是底线，守底摸高，建立科学的方法论。
2. 性能。通过技术手段降低资源消耗，平衡一致性和性能。
3. 安全。控制核按钮，收敛爆炸半径。
4. 成本效率。如何提升资源的利用率，如何构建可扩展和标准化的产品。