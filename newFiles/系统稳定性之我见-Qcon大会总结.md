---
dg-publish: true
title: 系统稳定性之我见-Qcon大会总结
createTime: 2023-07-09 19:47  
---

## 如何设计一个高可用的系统
我们用标题来谈一谈主流市面上常见的常见系统稳定性解决方案

首先是**流量入口端**，看下虎牙是怎么处理流量调度的

### 虎牙多云调度

![[Pasted image 20230709214925.png]]

#### 打造流量调度平台

##### 1. DNS
1. 自建+云解析混合同时使用
2. IDC作为DNS后台，写入master，同步到各个云服务
3. 用云上弹性资源部署slave节点
		1. 用以做到扩容缩容
		2. 解析服务异常自动切换
4. 统一域名管理入口
	![[Pasted image 20230709224049.png]]		
5. nameServer打通微服务,k8s,dns信息,提供统一dns解析能力
		- 配置存放nacos，同步对应service和ip等信息到nameServer
		- dns管理后台同步对应dns信息到nameServer
		- 内部dns快速生效，主机Agent劫持DNS解析，实时同步服务信息
1. 基于标签和cmdb，智能解析
		- cmdb库拉去对应信息打标
		- nameServer根据请求方标签和匹配策列返回匹配的解析记录
##### 7层负载均衡
1. 选型使用[APISXIX](https://apisix.apache.org/zh/)
2. 利用Apisix插件快速扩展
3. 标准化，与内部系统打通
4. 域名维度配置全量增量更新，多云同步一致
5. 集群均分流量，网络，集群异常通过DNS屏蔽
6. 通过标签信息，在进行负载均衡前，将节点过滤
7. 单个指令操作，集群级快速生效，不需要逐个域名进行配置，秒级快速生效
![[Pasted image 20230530231703.png]]

接下来是**应用端**在可用性上探讨的内容

### 菜鸟服务可用性工具能力建设

#### 1. 统一的结构化日志
1. 主要元素有：事件、用户身份、系统表现、错误码，业务单号，单据状态

> [!info] 正常日志格式
> 
时间戳->业务场景->是否成功->耗时->错误码->错误信息->请求id->调用序号
timestamp->eventCode->success->rt->errorCode->errorMsg->traceId->rpcId

> [!ERROR] 异常日志格式
 时间戳->异常类->异常方法->异常行号->错误码->错误信息->请求id->堆栈
timestamp->clazz->method->lineNumber->errorCode->errorMsg->traceId-> exceptionStack

1. 场景入口日志
	- entrance.log
2. 出入参日志
	- biz.log
3. 下游调用日志
	- event.log
4. 异常日志
	- error.log

#### 2. 单笔全链路查询排查

1. 调用链路（一次完整RPC调用，traceId唯一）
2. 业务全链路（多次RPC调用，业务单号唯一）

#### 3. 主动识别单笔异常
1. 指标监控（流量、错误、延时、饱和度等），
2. 卡单监控，
3. 上下游数据一致性监控	

##### 上下游数据一致性

> binlog同步 -> 落库hbase -> 数据校验.

单日百亿条数据，验证上下游的数据一致性。

##### 重试平台
![[Pasted image 20230530004259.png]]

#### 4. 真实，无损的单笔异常注入
系统服务，容器、宿主机、网络、机房等基础设施，卡单异常注入，单据数据篡改

##### 产业互联网中混沌工程常见挑战：
1. 异常的注入不够真实
2. 真实异常不敢注入

##### 菜鸟使用的方式：
1. 数据旁路篡改，看一致性校验监控中是否得以发现
2. 构建测试流量

接下来我们看下美团中针对**核心服务**是如何进行做业务功能稳定性的优化的

### 美团履约平台调度引擎架构

#### 业务的定位特点
- 线上+线下履约过程的最后一环
- 保障商家，用户，骑士的体验
- 时效性强
- 稳定性要求极高

#### 稳定性优化

##### 数据内容的拆分
	1. 实时数据
		1. 可以水平拆分
		2. 业务数据变化频繁,对数据变化敏感
	2. 离线数据
		1. TB级别数据
		2. 难拆分
		3. 数据按照天维度更新

##### 有状态服务

1. 容量稳定侧,路由需要额外成本
	1. 做更细粒度容量管理
2. 状态重建难度大,需要缩短发布时间
	1. 发布
		1. 恢复状态,降低影响
	2. 弹性伸缩
		1. 状态迁移,使用数据快照
3. 状态存储溢出
	1. 设置内存容量上限,超过只落磁盘
	2. 牺牲读,降级读磁盘
	3. 分片迁移其他副本
	4. 自动恢复
4. 数据一致性
	1. 实时同步
	2. 分钟级检查修复
		1. 补数据
		2. 告警,检查问题产生原因

关注完应用端，我们关注下阿里云在**中间件**稳定性上做的内容

### 微服务架构探索

#### 1. 异地多活
同城容灾到异地中心容灾要保证
	- 流量切换
	- 数据不丢
	- 数据一直

![[Pasted image 20230710011123.png]]

如果选择异地冷备，容易出现 
	- 流量未验证
	- 成本高

所以一般采用争先冗宅:
 - 强中心的服务, 跨单元调用
 - 交易运行时:
	 - 中心75%
	 - 容灾机房 25%，其中强中心应用1%
- 容灾态:
	- 容灾机房:100 %

#### 2. 规模化后内核稳定性问题

要面向千万级微服务构建稳定的最小核心微服务内核

##### 1. dubbo接口注册导致问题
	1. 推送效率低
	2. 业务端内存占比高
	3. 地址信息大
解决办法 
1. 减少rpc的地址信息
	1. 只保留地址信息，地址发现聚合key
	2. 地址中心同步内容仅包括地址ip元数据
	3. 其他元数据在provider，存入MetaDataService
		1. consumer 感应md5,直接从producer直接去拉去配置
		2. 暴露更多治理数据
2. 新老业务兼容
	1. 双注册模式
		1. 接口+ 应用

##### 2. 注册中心同步的问题
	1. 稳定性问题。单点存储256G达到上限；网卡易打
	爆。
	2. 推送效率问题。集群间双写，实时性O(n^2)。单节
	点pub，客户端全量 sub。
	1. 一致性问题。
解决方案：
1. Session和Data分离，Data分片；流量过载保护；推送控制；请求拒绝策略。
2. 数据压缩（1:30）；合并推送请求；增量推送。
3. 最终一致性；推空保护。

#### 3. 一致性问题

SEATA 分布式事务

#### 4. 微服务的互联互通

1. 南北流量做到跨平台跨语言
	1. http协议
	2. 网关转换
		1. 性能低
		2. 转换有损,丢标
	3. 性能/扩展性高
2. dubbo 暴露多协议（grpc，rest）
![[Pasted image 20230710013659.png]]

**微服务大规模演进的思考** 

1. 稳定性。稳定性永远是底线，守底摸高，建立科学的方法论。
2. 性能。通过技术手段降低资源消耗，平衡一致性和性能。
3. 安全。控制核按钮，收敛爆炸半径。
4. 成本效率。如何提升资源的利用率，如何构建可扩展和标准化的产品。

接下来看下腾讯云kakfa的降本

### kafka稳定性与降本增效

**kafka常见问题** 
1. 节点,硬盘成本占比较高
2. 常见稳定性问题
	1. 客户端超时 
	2. 生产写入失败
	3. 生产写入慢
	4. 消费堆积
	5. 硬盘打满
	6. CPU打满 & GC严重 
	7. 节点、机房、可用区故障

#### 1.  通过弹性计算架构提供稳定性

##### 有状态kafka服务计算 => 无状态计算

1. 尽量迁移少量的老数据 => 【分层存储】
	1. 冷热数据分离
2. 计算存储分离，弹性的计算层
	1. 方案1 快速挂载
		1. 完全不管原数据
	2. 方案2 使用分布式文件系统
		1. 有部分同步的问题
	3. 方案3 计算存储分离架构
		1. proxy方案
			1. 内核不用改动
		2. 底层存储切换远端引擎
		3. 内核支持
			1. 方案改动大, 对现有系统不友好,如阿里云盘古

最终选择方案2+扩展

##### 弹性本地存储

- 云盘+ 运营调度系统
	- 目标是发现快速发现需要扩容or缩容
- 多云盘+ 多目录
	- 数据倾斜的问题要通过调度系统处理

![[Pasted image 20230710015757.png]]

通过更加廉价的存储，让kafka开启分词存储，开启分层存储后,先写本地在写远端,消费也要从远端拉取数据,读到本地.

#### 2. 集群自均衡(Self Rebalance)防止数据倾斜

**针对rebalance条件限制：
1. 校验Leader切换的影响 
2. 低峰执行均衡 
3. 均衡前的严格校验，如流量、网络限制 
4. 均衡对象的选择，比如白名单、黑名单

#### 总结
**稳定性优先下的成本优化策略
1. 稳定性 > 成本
2. 集群粒度差异化的成本优化策略。 
3. 更细致的运营调度分析体系，让时间差带来的价值。
4. 架构升级提升软件性能、按量付费、丰富产品特性 => 置换成本优化后SLA









